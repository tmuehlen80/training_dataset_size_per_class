{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86887a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prepare datasets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import models\n",
    "\n",
    "#import pyDOE\n",
    "\n",
    "#from dexpy.samplers import uniform_simplex_sample\n",
    "from scipy import spatial\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# for Thomas: please use venv_events_3810 for running this script\n",
    "\n",
    "# Prepare cifar dataset:\n",
    "print(\"prepare datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d5dae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [Errno 11001] getaddrinfo failed>\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error downloading train-images-idx3-ubyte.gz",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 22\u001b[0m\n\u001b[0;32m     12\u001b[0m transform_test \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose(\n\u001b[0;32m     13\u001b[0m     [\u001b[39m#transforms.Resize(size=(224, 224)), # necessary only for VGG16\u001b[39;00m\n\u001b[0;32m     14\u001b[0m      transforms\u001b[39m.\u001b[39mToTensor(),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     17\u001b[0m                                      std\u001b[39m=\u001b[39m[\u001b[39m0.229\u001b[39m, \u001b[39m0.224\u001b[39m, \u001b[39m0.225\u001b[39m])]     \n\u001b[0;32m     18\u001b[0m      )\n\u001b[0;32m     21\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m128\u001b[39m\n\u001b[1;32m---> 22\u001b[0m trainset_subset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39;49mFashionMNIST(root\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m./data\u001b[39;49m\u001b[39m'\u001b[39;49m, train\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, download\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     23\u001b[0m trainloader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(trainset_subset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m     25\u001b[0m testset \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mFashionMNIST(root\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39m./data\u001b[39m\u001b[39m'\u001b[39m, train\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, transform\u001b[39m=\u001b[39mtransform_test)\n",
      "File \u001b[1;32mc:\\Users\\tmueh\\anaconda3\\envs\\venv_tdss\\lib\\site-packages\\torchvision\\datasets\\mnist.py:99\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[1;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \u001b[39mif\u001b[39;00m download:\n\u001b[1;32m---> 99\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdownload()\n\u001b[0;32m    101\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_exists():\n\u001b[0;32m    102\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mDataset not found. You can use download=True to download it\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\tmueh\\anaconda3\\envs\\venv_tdss\\lib\\site-packages\\torchvision\\datasets\\mnist.py:195\u001b[0m, in \u001b[0;36mMNIST.download\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 195\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError downloading \u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error downloading train-images-idx3-ubyte.gz"
     ]
    }
   ],
   "source": [
    "\n",
    "# please take care that the same transforms are used in full training and in the algo below.\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.RandomHorizontalFlip(),\n",
    "     transforms.RandomCrop(32, 4),   \n",
    "     transforms.ToTensor(),\n",
    "     #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])]     \n",
    "     )\n",
    "\n",
    "transform_test = transforms.Compose(\n",
    "    [#transforms.Resize(size=(224, 224)), # necessary only for VGG16\n",
    "     transforms.ToTensor(),\n",
    "     #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])]     \n",
    "     )\n",
    "\n",
    "\n",
    "batch_size = 128\n",
    "trainset_subset = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True)\n",
    "trainloader = torch.utils.data.DataLoader(trainset_subset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff35115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6805c667",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8a95e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e81ee85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4517095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import warnings\n",
    "from pandas.core.common import SettingWithCopyWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "os.chdir(\"..\")\n",
    "os.getcwd()\n",
    "\n",
    "from platform import python_version\n",
    "print(python_version())\n",
    "\n",
    "import importlib.util\n",
    "\n",
    "spec_data_pred = importlib.util.spec_from_file_location(\"data_pred\", \"src\\\\data_prep.py\")\n",
    "prep_data = importlib.util.module_from_spec(spec_data_pred)\n",
    "spec_data_pred.loader.exec_module(prep_data)\n",
    "\n",
    "spec_plotting_printing = importlib.util.spec_from_file_location(\"plotting_printing\", \"src\\\\plotting_printing.py\")\n",
    "plotting_printing = importlib.util.module_from_spec(spec_plotting_printing)\n",
    "spec_plotting_printing.loader.exec_module(plotting_printing)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd9c014f",
   "metadata": {},
   "source": [
    "### Purpose of this notebook: \n",
    "\n",
    "# Doing exeriments with different scaling laws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec15a07",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf49b4",
   "metadata": {},
   "source": [
    "Please run `cifar10_datasetsize_multidim.py` before running this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c88e35e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"exerimental\"\n",
    "# https://github.com/google-research/google-research/blob/master/revisiting_neural_scaling_laws/methods/m4.py\n",
    "# https://arxiv.org/pdf/2209.06640.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd13414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
      "\\begin{tabular}{lrrrrrrrrrrrrr}\n",
      "\\toprule\n",
      "{} &  accs &  plane &   car &  bird &    cat &    deer &    dog &    frog &  horse &   ship &  truck &  epochs\\_trained &  total\\_training\\_size \\\\\n",
      "\\midrule\n",
      "0 &  0.20 & 145.00 & 31.00 & 97.00 & 496.00 & 1096.00 & 307.00 & 2382.00 &   9.00 & 373.00 &  63.00 &              20 &              4999.00 \\\\\n",
      "1 &  0.25 & 145.00 & 31.00 & 97.00 & 496.00 & 1096.00 & 307.00 & 2382.00 &   9.00 & 373.00 &  63.00 &              25 &              4999.00 \\\\\n",
      "2 &  0.24 & 145.00 & 31.00 & 97.00 & 496.00 & 1096.00 & 307.00 & 2382.00 &   9.00 & 373.00 &  63.00 &              30 &              4999.00 \\\\\n",
      "3 &  0.26 & 145.00 & 31.00 & 97.00 & 496.00 & 1096.00 & 307.00 & 2382.00 &   9.00 & 373.00 &  63.00 &              35 &              4999.00 \\\\\n",
      "4 &  0.29 & 145.00 & 31.00 & 97.00 & 496.00 & 1096.00 & 307.00 & 2382.00 &   9.00 & 373.00 &  63.00 &              40 &              4999.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itterations</th>\n",
       "      <th>accs</th>\n",
       "      <th>training_times</th>\n",
       "      <th>plane</th>\n",
       "      <th>car</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "      <th>epochs_trained</th>\n",
       "      <th>total_training_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>95.387190</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>20</td>\n",
       "      <td>45500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>95.093551</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>25</td>\n",
       "      <td>45500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7774</td>\n",
       "      <td>94.994801</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>30</td>\n",
       "      <td>45500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7967</td>\n",
       "      <td>94.904114</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>35</td>\n",
       "      <td>45500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8035</td>\n",
       "      <td>95.364757</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>40</td>\n",
       "      <td>45500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itterations    accs  training_times   plane     car    bird     cat  \\\n",
       "0            0  0.7703       95.387190  5000.0  4500.0  4500.0  4500.0   \n",
       "1            0  0.7833       95.093551  5000.0  4500.0  4500.0  4500.0   \n",
       "2            0  0.7774       94.994801  5000.0  4500.0  4500.0  4500.0   \n",
       "3            0  0.7967       94.904114  5000.0  4500.0  4500.0  4500.0   \n",
       "4            0  0.8035       95.364757  5000.0  4500.0  4500.0  4500.0   \n",
       "\n",
       "     deer     dog    frog   horse    ship   truck  epochs_trained  \\\n",
       "0  4500.0  4500.0  4500.0  4500.0  4500.0  4500.0              20   \n",
       "1  4500.0  4500.0  4500.0  4500.0  4500.0  4500.0              25   \n",
       "2  4500.0  4500.0  4500.0  4500.0  4500.0  4500.0              30   \n",
       "3  4500.0  4500.0  4500.0  4500.0  4500.0  4500.0              35   \n",
       "4  4500.0  4500.0  4500.0  4500.0  4500.0  4500.0              40   \n",
       "\n",
       "   total_training_size  \n",
       "0              45500.0  \n",
       "1              45500.0  \n",
       "2              45500.0  \n",
       "3              45500.0  \n",
       "4              45500.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 10800)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itterations</th>\n",
       "      <th>accs</th>\n",
       "      <th>training_times</th>\n",
       "      <th>plane</th>\n",
       "      <th>car</th>\n",
       "      <th>bird</th>\n",
       "      <th>cat</th>\n",
       "      <th>deer</th>\n",
       "      <th>dog</th>\n",
       "      <th>frog</th>\n",
       "      <th>horse</th>\n",
       "      <th>ship</th>\n",
       "      <th>truck</th>\n",
       "      <th>epochs_trained</th>\n",
       "      <th>total_training_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7703</td>\n",
       "      <td>95.387190</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>20</td>\n",
       "      <td>45500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>95.093551</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>25</td>\n",
       "      <td>45500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7774</td>\n",
       "      <td>94.994801</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>30</td>\n",
       "      <td>45500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.7967</td>\n",
       "      <td>94.904114</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>35</td>\n",
       "      <td>45500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.8035</td>\n",
       "      <td>95.364757</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>40</td>\n",
       "      <td>45500.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itterations    accs  training_times   plane     car    bird     cat  \\\n",
       "0            0  0.7703       95.387190  5000.0  4500.0  4500.0  4500.0   \n",
       "1            0  0.7833       95.093551  5000.0  4500.0  4500.0  4500.0   \n",
       "2            0  0.7774       94.994801  5000.0  4500.0  4500.0  4500.0   \n",
       "3            0  0.7967       94.904114  5000.0  4500.0  4500.0  4500.0   \n",
       "4            0  0.8035       95.364757  5000.0  4500.0  4500.0  4500.0   \n",
       "\n",
       "     deer     dog    frog   horse    ship   truck  epochs_trained  \\\n",
       "0  4500.0  4500.0  4500.0  4500.0  4500.0  4500.0              20   \n",
       "1  4500.0  4500.0  4500.0  4500.0  4500.0  4500.0              25   \n",
       "2  4500.0  4500.0  4500.0  4500.0  4500.0  4500.0              30   \n",
       "3  4500.0  4500.0  4500.0  4500.0  4500.0  4500.0              35   \n",
       "4  4500.0  4500.0  4500.0  4500.0  4500.0  4500.0              40   \n",
       "\n",
       "   total_training_size  \n",
       "0              45500.0  \n",
       "1              45500.0  \n",
       "2              45500.0  \n",
       "3              45500.0  \n",
       "4              45500.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_from_file = pd.read_csv(\"csv_files/Cifar10_acc_subsets_thomas_batch_size_512_mixture_design_maximin_subsetsize_45000_20230705.csv\")\n",
    "results_val_from_file = pd.read_csv(\"csv_files/Cifar10_acc_subsets_thomas_batch_size_512_mixture_design_maximin_subsetsize_45000_val_20230708.csv\")\n",
    "results_4500_from_file = pd.read_csv(\"csv_files/Cifar10_acc_subsets_jelena_batch_size_512_mixture_design_maximin_subsetsize_4500_20230715.csv\")\n",
    "\n",
    "#prep_data\n",
    "#classes, xdata, y, xdata_val, y_val, xdata_pred, xdata_4500, y_4500, results, results_val, results_4500, results_pred, results_4500_orig, results_pred_orig, xdata_last_epoch, y_last_epoch, xdata_val_last_epoch, y_val_last_epoch, xdata_total_n_epoch, xdata_val_total_n_epoch = prep_data.prep_data_all_epochs(results_from_file, \n",
    "#              results_val_from_file, \n",
    "#              results_4500_from_file, \n",
    "#              min_epoch = 20)\n",
    "              \n",
    "data_dict = prep_data.prep_data_all_epochs(results_from_file, \n",
    "              results_val_from_file, \n",
    "              results_4500_from_file, \n",
    "              min_epoch = 20)\n",
    "\n",
    "# the following unpacks all dict items into a corresonding variable:\n",
    "locals().update(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d5f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"otentially to be deleted \"\n",
    "props = dict(boxstyle='round', facecolor='white', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f82246a",
   "metadata": {},
   "source": [
    "# m4 from paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc99d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_name = \"m4\"\n",
    "### hm, doing m4 in the same way as the other functions is rather challenging, as it is only defined implicitely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef82287",
   "metadata": {},
   "source": [
    "# powerlaw - full linear option"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3b4927",
   "metadata": {},
   "source": [
    "### Full option: \n",
    "\n",
    "* Fit a power law model, having the count of each level as input ... \n",
    "* ... and the number of epochs as an input as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08771bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_name = \"accs_hat_classes_linear_epoch_linear\"\n",
    "\n",
    "def func(x, a: float, b: float, c: float, d0:float, d1:float, d2:float, d3:float, d4:float, d5:float, d6:float, d7:float, d8:float, d9:float, d_epochs:float) -> float:\n",
    "    x0 = x[0]\n",
    "    x1 = x[1]\n",
    "    x2 = x[2]\n",
    "    x3 = x[3]\n",
    "    x4 = x[4]\n",
    "    x5 = x[5]\n",
    "    x6 = x[6]\n",
    "    x7 = x[7]\n",
    "    x8 = x[8]\n",
    "    x9 = x[9]\n",
    "    epochs_trained = x[10]\n",
    "    #result = a + d * (2 / np.pi) * np.arctan(b * (d0*x0 + d1*x1 + d2*x2 + d3*x3 + d4*x4 + d5*x5 + d6*x6 + d7*x7 + d8*x8 + d9*x9 + d_epochs*epochs_trained) + c)\n",
    "    #result = a + d * (2 / np.pi) * np.arctan(b * (d0*x0 + d1*x1 + d2*x2 + d3*x3 + d4*x4 + d5*x5 + d6*x6 + d7*x7 + d8*x8 + d9*x9 + d_epochs*epochs_trained) + c)\n",
    "    result = a + ((d0*x0 + d1*x1 + d2*x2 + d3*x3 + d4*x4 + d5*x5 + d6*x6 + d7*x7 + d8*x8 + d9*x9 + d_epochs*epochs_trained)**b) * c\n",
    "    return result \n",
    "\n",
    "np.random.seed(seed=4213523)\n",
    "p0 = np.random.uniform(low=0, high=1, size = 14)\n",
    "converged = False\n",
    "try:\n",
    "    params, params_cov = curve_fit(func, xdata, y, maxfev=200000, p0=p0, bounds=(-10, 10))\n",
    "    converged = True\n",
    "except:\n",
    "    print(\"did not converge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97c2580",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata.shape\n",
    "print(xdata.shape)\n",
    "np.delete(xdata, 1, axis=1).shape\n",
    "print(y.shape)\n",
    "print(np.delete(y, 1).shape)\n",
    "xdata[:,122]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60711b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a47b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(tm[1]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59550e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#func(xdata, *p0)\n",
    "\n",
    "from tqdm import tqdm\n",
    "from typing import Tuple\n",
    "\n",
    "def predict_leave_one_out(x: np.ndarray,\n",
    "                          y: np.ndarray,\n",
    "                          f: callable,\n",
    "                          p0=None,\n",
    "                          bounds=(-np.inf, np.inf),\n",
    "                          sample=None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    '''\n",
    "    Fit power law function by the leave one out principle. Perform prediction for the left out sample.\n",
    "\n",
    "    Args:\n",
    "        x: array containing the x datapoints used to fit a power law function\n",
    "        y: array containing the y datapoints used to fit a power law function\n",
    "        f: the model/fitting function, f(x, ...). See curve_fit for further details.\n",
    "        p0: array_like, optional argument stating the nitial guess for the parameters (length N).\n",
    "            See curve_fit for further details.\n",
    "        bounds: 2-tuple of array_like, optional argument stating the lower and upper bounds on parameters. Defaults\n",
    "            to no bounds. See curve_fit for further details.\n",
    "\n",
    "    Returns:\n",
    "        Tuple containing arrays of the ground_truths and the predictions which were calculated by the leave one out\n",
    "        principle.\n",
    "    '''\n",
    "    test_ground_truth = []\n",
    "    test_predictions = []\n",
    "    size = x.shape[1] - 1\n",
    "    if sample is None:\n",
    "        rangelist = range(size)\n",
    "    else: \n",
    "        rangelist = np.random.choice(size, sample, replace = False).tolist()\n",
    "    for i in tqdm(rangelist):\n",
    "        train_x = np.delete(x, i, axis=1)\n",
    "        test_x = x[:, i]\n",
    "        train_y = np.delete(y, i)\n",
    "        test_y = y[i]\n",
    "        params, _ = curve_fit(f, train_x, train_y, maxfev=200000, p0=p0, bounds=bounds)\n",
    "        y_predicted = f(test_x, *params)\n",
    "        test_ground_truth.append(test_y)\n",
    "        test_predictions.append(y_predicted)\n",
    "    return test_ground_truth, test_predictions\n",
    "\n",
    "tm = predict_leave_one_out(xdata, y, func, p0, bounds=(-10, 10), sample=25)\n",
    "stddev = np.sqrt(np.sum((np.array(tm[0]) - np.array(tm[1]))**2) / len(tm[1]))\n",
    "stddev\n",
    "\n",
    "# hmm, this still does not work well...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fec091",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"a\", \"b\", \"c\"]\n",
    "param_names = param_names + classes + [\"epoch\"]\n",
    "if converged:\n",
    "    plotting_printing.plotting_printing_all_epochs(func, model_type, y_hat_name, xdata, y, param_names,  params, results, xdata_val, y_val, results_val, xdata_4500, xdata_pred, results_pred_orig, results_4500, results_4500_orig, saving_plots=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eada4690",
   "metadata": {},
   "source": [
    "### using an arctan effect for every class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58158b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_name = \"exerimental\"\n",
    "\n",
    "def func(x, a: float, b: float, c: float, d0:float, d0_2:float, d1:float, d1_2:float, d2:float, d2_2:float, d3:float, d3_2:float, d4:float, d4_2:float, d5:float, d5_2:float, d6:float, d6_2:float, d7:float, d7_2:float, d8:float, d8_2:float, d9:float, d9_2:float, d_epochs:float, d_epoch_2:float) -> float:\n",
    "    x0 = x[0]\n",
    "    x1 = x[1]\n",
    "    x2 = x[2]\n",
    "    x3 = x[3]\n",
    "    x4 = x[4]\n",
    "    x5 = x[5]\n",
    "    x6 = x[6]\n",
    "    x7 = x[7]\n",
    "    x8 = x[8]\n",
    "    x9 = x[9]\n",
    "    epochs_trained = x[10]\n",
    "    #result = a + ((d0* np.arctan(d0_2 * x0) + d1* np.arctan(d1_2 * x1)  + d2* np.arctan(d2_2 * x2) + d3 * np.arctan(d3_2 * x3) + d4 * np.arctan(d4_2 * x4) + d5 * np.arctan(d5_2 * x5) + d6 * np.arctan(d6_2 * x6) + d7 * np.arctan(d7_2 * x7) + d8 * np.arctan(d8_2 * x8) + d9 * np.arctan(d9_2 * x9) + d_epochs*np.arctan(d_epoch_2 * epochs_trained))**(b + b1 * (x0 + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9))) * c\n",
    "    #result = a + ((d0* np.arctan(d0_2 * x0) + d1* np.arctan(d1_2 * x1)  + d2* np.arctan(d2_2 * x2) + d3 * np.arctan(d3_2 * x3) + d4 * np.arctan(d4_2 * x4) + d5 * np.arctan(d5_2 * x5) + d6 * np.arctan(d6_2 * x6) + d7 * np.arctan(d7_2 * x7) + d8 * np.arctan(d8_2 * x8) + d9 * np.arctan(d9_2 * x9) + d_epochs*np.arctan(d_epoch_2 * epochs_trained))**(b + b1 * (x0 + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9))) * (c + c1 * (x0 + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9))\n",
    "    #result = a + a1 *(x0 + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9) + ((d0* np.arctan(d0_2 * x0) + d1* np.arctan(d1_2 * x1)  + d2* np.arctan(d2_2 * x2) + d3 * np.arctan(d3_2 * x3) + d4 * np.arctan(d4_2 * x4) + d5 * np.arctan(d5_2 * x5) + d6 * np.arctan(d6_2 * x6) + d7 * np.arctan(d7_2 * x7) + d8 * np.arctan(d8_2 * x8) + d9 * np.arctan(d9_2 * x9) + d_epochs*np.arctan(d_epoch_2 * epochs_trained))**(b + b1 * (x0 + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9))) * (c + c1 * (x0 + x1 + x2 + x3 + x4 + x5 + x6 + x7 + x8 + x9)) # did not converge,took long time\n",
    "    #result = a + (2 / np.pi) * np.arctan(b * (d0* np.arctan(d0_2 * x0) + d1* np.arctan(d1_2 * x1)  + d2* np.arctan(d2_2 * x2) + d3 * np.arctan(d3_2 * x3) + d4 * np.arctan(d4_2 * x4) + d5 * np.arctan(d5_2 * x5) + d6 * np.arctan(d6_2 * x6) + d7 * np.arctan(d7_2 * x7) + d8 * np.arctan(d8_2 * x8) + d9 * np.arctan(d9_2 * x9) + d_epochs*np.arctan(d_epoch_2 * epochs_trained)) + c)\n",
    "    #result = a + (2 / np.pi) * np.arctan(b * (d0* np.arctan(d0_2 + x0) + d1* np.arctan(d1_2 + x1)  + d2* np.arctan(d2_2 + x2) + d3 * np.arctan(d3_2 + x3) + d4 * np.arctan(d4_2 + x4) + d5 * np.arctan(d5_2 + x5) + d6 * np.arctan(d6_2 + x6) + d7 * np.arctan(d7_2 + x7) + d8 * np.arctan(d8_2 + x8) + d9 * np.arctan(d9_2 + x9) + d_epochs*np.arctan(d_epoch_2 + epochs_trained)) + c) \n",
    "    #result = a + (2 / np.pi) * np.arctan(b * (d0* np.log(d0_2 + x0) + d1* np.log(d1_2 + x1)  + d2* np.log(d2_2 + x2) + d3 * np.log(d3_2 + x3) + d4 * np.log(d4_2 + x4) + d5 * np.log(d5_2 + x5) + d6 * np.log(d6_2 + x6) + d7 * np.log(d7_2 + x7) + d8 * np.log(d8_2 + x8) + d9 * np.log(d9_2 + x9) + d_epochs*np.log(d_epoch_2 + epochs_trained)) + c)# this one works quite ok for the 45oo examle\n",
    "    #result = a * np.log(d0* np.arctan(d0_2 * x0) + d1* np.arctan(d1_2 * x1)  + d2* np.arctan(d2_2 * x2) + d3 * np.arctan(d3_2 * x3) + d4 * np.arctan(d4_2 * x4) + d5 * np.arctan(d5_2 * x5) + d6 * np.arctan(d6_2 * x6) + d7 * np.arctan(d7_2 * x7) + d8 * np.arctan(d8_2 * x8) + d9 * np.arctan(d9_2 * x9) + d_epochs*np.arctan(d_epoch_2 * epochs_trained) + b) +  c    \n",
    "    result = a * np.log(d0 * x0 ** d0_2  + d1 * x1 ** d1_2 + d3 * x3 ** d3_2 + d4 * x4 ** d4_2 + d5 * x5 ** d5_2 + d6 * x6 ** d6_2 + d7 * x7 ** d7_2 + d8 * x8 ** d8_2 + d9 * x9 ** d9_2 + d_epochs* epochs_trained ** d_epoch_2 + b) +  c    \n",
    "    return result\n",
    "\n",
    "np.random.seed(seed=421530)\n",
    "n_p = 25\n",
    "p0 = np.random.uniform(low=0.2, high=1, size = n_p)\n",
    "converged = False\n",
    "#try:\n",
    "params, params_cov = curve_fit(func, xdata, y, maxfev=200000, p0=p0, bounds=(1e-5, 50))\n",
    "converged = True\n",
    "#except:\n",
    "#    print(\"did not converge\")\n",
    "np.diag(params_cov)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e944daf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tm = func(xdata_val, *params)\n",
    "type(tm)\n",
    "pd.DataFrame(xdata_val.T).loc[pd.Series(tm).isna(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747f0c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"a\", \"b\",  \"c\"]\n",
    "for c in classes:\n",
    "    param_names = param_names + [f\"{c}_1\", f\"{c}_2\"]\n",
    "param_names = param_names + [\"epoch_1\", \"epoch_2\"]\n",
    "\n",
    "if converged:\n",
    "    plotting_printing.plotting_printing_all_epochs(func, model_type, y_hat_name, xdata, y, param_names,  params, results, xdata_val, y_val, results_val, xdata_4500, xdata_pred, results_pred_orig, results_4500, results_4500_orig, saving_plots=False, is_2param=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf008880",
   "metadata": {},
   "source": [
    "# all class counts linear, but including quadratic term for epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "776272e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_name = \"accs_hat_classes_linear_epoch_sq\"\n",
    "\n",
    "def func(x, a: float, b: float, c: float, d0:float, d1:float, d2:float, d3:float, d4:float, d5:float, d6:float, d7:float, d8:float, d9:float, d_epochs:float, d_epochs_sq:float) -> float:\n",
    "    x0 = x[0]\n",
    "    x1 = x[1]\n",
    "    x2 = x[2]\n",
    "    x3 = x[3]\n",
    "    x4 = x[4]\n",
    "    x5 = x[5]\n",
    "    x6 = x[6]\n",
    "    x7 = x[7]\n",
    "    x8 = x[8]\n",
    "    x9 = x[9]\n",
    "    epochs_trained = x[10]\n",
    "    return a + ((d0*x0 + d1*x1 + d2*x2 + d3*x3 + d4*x4 + d5*x5 + d6*x6 + d7*x7 + d8*x8 + d9*x9 + d_epochs*epochs_trained + d_epochs_sq * epochs_trained**2)**b) * c\n",
    "\n",
    "np.random.seed(seed=42132457)\n",
    "n_p = 15\n",
    "p0 = np.random.uniform(low=0, high=1, size = n_p)\n",
    "converged = False\n",
    "try:\n",
    "    params, params_cov = curve_fit(func, xdata, y, maxfev=200000, p0=p0, bounds=(-10, 10))\n",
    "    converged = True\n",
    "except:\n",
    "    print(\"did not converge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25358064",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = [\"a\", \"b\", \"c\"]\n",
    "param_names = param_names + classes + [\"epoch\", \"epoch**2\"]\n",
    "\n",
    "if converged:\n",
    "    plotting_printing.plotting_printing_all_epochs(func, model_type, y_hat_name, xdata, y, param_names,  params, results, xdata_val, y_val, results_val, xdata_4500, xdata_pred, results_pred_orig, results_4500, results_4500_orig, saving_plots=False, is_2param=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82354c6f",
   "metadata": {},
   "source": [
    "# using all epochs, but just overall training dataset size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907ca964",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "y_hat_name = \"accs_hat_total_n_epoch\"\n",
    "\n",
    "def func(x, a: float, b: float, c: float, d_total_n:float, d_epochs:float) -> float:\n",
    "    x_total_n = x[0]\n",
    "    x_epoch = x[1]\n",
    "    return a + ((d_total_n * x_total_n + d_epochs*x_epoch)**b) * c\n",
    "\n",
    "np.random.seed(seed=4342133)\n",
    "\n",
    "p0 = np.random.uniform(low=0, high=1, size = 5)\n",
    "converged = False\n",
    "try:\n",
    "    params, params_cov = curve_fit(func, xdata_total_n_epoch, y, maxfev=200000, p0=p0, bounds=(-10, 10))\n",
    "    converged = True\n",
    "except:\n",
    "    print(\"did not converge\")\n",
    "\n",
    "\n",
    "\"continue from here\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be645a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "func_powerlaw = func\n",
    "\n",
    "if converged:\n",
    "    param_names = [\"a\", \"b\", \"c\", \"total_n\", \"epoch\"]\n",
    "    param_df = pd.DataFrame({\"param_name\": param_names, \"param_value\": params})\n",
    "    param_df = param_df.set_index(\"param_name\").T\n",
    "    HTML(display(param_df))\n",
    "    print(param_df.to_latex(float_format=\"{:.2f}\".format))\n",
    "    y_hat = func_powerlaw(xdata_total_n_epoch, *params)\n",
    "    print(\"train avg loss:\")\n",
    "    print(((y_hat - y)**2).mean())\n",
    "    # dataframe for plotting:\n",
    "    y_hat_name = \"accs_hat_total_n_epoch\"\n",
    "    results[y_hat_name] = y_hat\n",
    "    sns.scatterplot(data = results, x=\"accs\", y = y_hat_name, hue = \"epochs_trained\")\n",
    "    plt.xlim((0.05, 0.9))\n",
    "    plt.ylim((0.05, 0.9))\n",
    "    plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (5, 5)))\n",
    "    plt.text(x=0.1, y=0.8, s=f\"r-sq: {np.round(metrics.r2_score(results.accs, results[y_hat_name]), 3)}\", bbox=props)\n",
    "    plt.savefig(f\"paper/plots/powerlaw_train_{y_hat_name}.jpg\")\n",
    "    plt.show()\n",
    "    print(\"rsquare train:\")\n",
    "    print(metrics.r2_score(results.accs, results[y_hat_name]))\n",
    "    # val data:\n",
    "    y_val_hat = func_powerlaw(xdata_val_total_n_epoch, *params)\n",
    "    print(\"val avg loss:\")\n",
    "    print(((y_val_hat - y_val)**2).mean())\n",
    "    # dataframe for plotting:\n",
    "    results_val[y_hat_name] = y_val_hat\n",
    "\n",
    "    sns.scatterplot(data = results_val, x=\"accs\", y = y_hat_name, hue = \"epochs_trained\")\n",
    "    plt.xlim((0.05, 0.9))\n",
    "    plt.ylim((0.05, 0.9))\n",
    "    plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (5, 5)))\n",
    "    plt.text(x=0.1, y=0.8, s=f\"r-sq: {np.round(metrics.r2_score(results_val.accs, results_val[y_hat_name]), 3)}\", bbox=props)\n",
    "    plt.savefig(f\"paper/plots/powerlaw_val_{y_hat_name}.jpg\")\n",
    "    plt.show()\n",
    "    print(\"rsquare val:\")\n",
    "    print(metrics.r2_score(results_val.accs, results_val[y_hat_name]))\n",
    "\n",
    "    acc_pred = func_powerlaw(xpred, *params)\n",
    "    results_pred_orig[\"acc_pred\"] = acc_pred\n",
    "    sns.scatterplot(data = results_pred_orig, x = \"total_training_size\", y = \"acc_pred\", hue=\"epochs_trained\")\n",
    "    plt.show()\n",
    "    display(results_pred_orig.head(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72e3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_powerlaw(x, a: float, b: float, c: float, d_total_n:float, d_epochs:float, d_epochs_sq:float) -> float:\n",
    "    x_total_n = x[0]\n",
    "    x_epoch = x[1]\n",
    "    return a + ((d_total_n * x_total_n + d_epochs*x_epoch + d_epochs_sq*x_epoch**2)**b) * c\n",
    "\n",
    "np.random.seed(seed=959486)\n",
    "p0 = np.random.uniform(low=0, high=1, size = 6)\n",
    "converged = False\n",
    "try:\n",
    "    params, params_cov = curve_fit(func_powerlaw, xdata_total_n_epoch, y, maxfev=200000, p0=p0, bounds=(-10, 10))\n",
    "    converged = True\n",
    "except:\n",
    "    print(\"did not converge\")\n",
    "\n",
    "if converged:\n",
    "    param_names = [\"a\", \"b\", \"c\", \"total_n\", \"epoch\", \"epoch_sq\"]\n",
    "    param_df = pd.DataFrame({\"param_name\": param_names, \"param_value\": params})\n",
    "    param_df = param_df.set_index(\"param_name\").T\n",
    "    HTML(display(param_df))\n",
    "    print(param_df.to_latex())\n",
    "    y_hat = func_powerlaw(xdata_total_n_epoch, *params)\n",
    "    print(\"train avg loss:\")\n",
    "    print(((y_hat - y)**2).mean())\n",
    "    # dataframe for plotting:\n",
    "    y_hat_name = \"accs_hat_total_n_epoch_sq\"\n",
    "    results[y_hat_name] = y_hat\n",
    "    sns.scatterplot(data = results, x=\"accs\", y = y_hat_name, hue = \"epochs_trained\")\n",
    "    plt.xlim((0.05, 0.9))\n",
    "    plt.ylim((0.05, 0.9))\n",
    "    plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (5, 5)))\n",
    "    plt.text(x=0.1, y=0.8, s=f\"r-sq: {np.round(metrics.r2_score(results.accs, results[y_hat_name]), 3)}\", bbox=props)\n",
    "    plt.savefig(f\"paper/plots/powerlaw_train_{y_hat_name}.jpg\")\n",
    "    plt.show()\n",
    "    print(\"rsquare train:\")\n",
    "    print(metrics.r2_score(results.accs, results[y_hat_name]))\n",
    "    # val data:\n",
    "    y_val_hat = func_powerlaw(xdata_val_total_n_epoch, *params)\n",
    "    print(\"val avg loss:\")\n",
    "    print(((y_val_hat - y_val)**2).mean())\n",
    "    # dataframe for plotting:\n",
    "    results_val[y_hat_name] = y_val_hat\n",
    "\n",
    "    sns.scatterplot(data = results_val, x=\"accs\", y = y_hat_name, hue = \"epochs_trained\")\n",
    "    plt.xlim((0.05, 0.9))\n",
    "    plt.ylim((0.05, 0.9))\n",
    "    plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (5, 5)))\n",
    "    plt.text(x=0.1, y=0.8, s=f\"r-sq: {np.round(metrics.r2_score(results_val.accs, results_val[y_hat_name]), 3)}\", bbox=props)\n",
    "    plt.savefig(f\"paper/plots/powerlaw_val_{y_hat_name}.jpg\")\n",
    "    plt.show()\n",
    "    print(\"rsquare val:\")\n",
    "    print(metrics.r2_score(results_val.accs, results_val[y_hat_name]))\n",
    "\n",
    "    acc_pred = func_powerlaw(xpred, *params)\n",
    "    results_pred_orig[\"acc_pred\"] = acc_pred\n",
    "    sns.scatterplot(data = results_pred_orig, x = \"total_training_size\", y = \"acc_pred\", hue=\"epochs_trained\")\n",
    "    plt.show()\n",
    "    display(results_pred_orig.head(30))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128d5939",
   "metadata": {},
   "source": [
    "### Using the arctan trick also for the total_n model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249c58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func_powerlaw(x, a: float, b: float, c: float, d_total_n:float, d_total_n_2:float, d_epochs:float, d_epochs_2:float) -> float:\n",
    "    x_total_n = x[0]\n",
    "    x_epoch = x[1]\n",
    "    return a + ((d_total_n * np.arctan(d_total_n_2 * x_total_n) + d_epochs* np.arctan( d_epochs_2 * x_epoch))**b) * c\n",
    "\n",
    "np.random.seed(seed=92548)\n",
    "n_p = 7\n",
    "p0 = np.random.uniform(low=0, high=1, size = n_p)\n",
    "converged = False\n",
    "try:\n",
    "    params, params_cov = curve_fit(func_powerlaw, xdata_total_n_epoch, y, maxfev=200000, p0=p0, bounds=(-10, 10))\n",
    "    converged = True\n",
    "except:\n",
    "    print(\"did not converge\")\n",
    "\n",
    "if converged:\n",
    "    param_names = [\"a\", \"b\", \"c\", \"total_n\", \"total_n_2\", \"epoch\", \"epoch_2\"]\n",
    "    param_df = pd.DataFrame({\"param_name\": param_names, \"param_value\": params})\n",
    "    param_df = param_df.set_index(\"param_name\").T\n",
    "    HTML(display(param_df))\n",
    "    print(param_df.to_latex())\n",
    "    y_hat = func_powerlaw(xdata_total_n_epoch, *params)\n",
    "    print(\"train avg loss:\")\n",
    "    print(((y_hat - y)**2).mean())\n",
    "    # dataframe for plotting:\n",
    "    y_hat_name = \"accs_hat_total_n_epoch_arctan\"\n",
    "    results[y_hat_name] = y_hat\n",
    "    sns.scatterplot(data = results, x=\"accs\", y = y_hat_name, hue = \"epochs_trained\")\n",
    "    plt.xlim((0.05, 0.9))\n",
    "    plt.ylim((0.05, 0.9))\n",
    "    plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (5, 5)))\n",
    "    plt.text(x=0.1, y=0.8, s=f\"r-sq: {np.round(metrics.r2_score(results.accs, results[y_hat_name]), 3)}\", bbox=props)\n",
    "    plt.savefig(f\"paper/plots/powerlaw_train_{y_hat_name}.jpg\")\n",
    "    plt.show()\n",
    "    print(\"rsquare train:\")\n",
    "    print(metrics.r2_score(results.accs, results[y_hat_name]))\n",
    "    print(1 - (1 - metrics.r2_score(results.accs, results[y_hat_name])) * (xdata_total_n_epoch.shape[1] - 1) / (xdata_total_n_epoch.shape[1] - n_p - 1))\n",
    "    # val data:\n",
    "    y_val_hat = func_powerlaw(xdata_val_total_n_epoch, *params)\n",
    "    print(\"val avg loss:\")\n",
    "    print(((y_val_hat - y_val)**2).mean())\n",
    "    # dataframe for plotting:\n",
    "    results_val[y_hat_name] = y_val_hat\n",
    "\n",
    "    sns.scatterplot(data = results_val, x=\"accs\", y = y_hat_name, hue = \"epochs_trained\")\n",
    "    plt.xlim((0.05, 0.9))\n",
    "    plt.ylim((0.05, 0.9))\n",
    "    plt.axline((0, 0), slope=1, color=\"black\", linestyle=(0, (5, 5)))\n",
    "    plt.text(x=0.1, y=0.8, s=f\"r-sq: {np.round(metrics.r2_score(results_val.accs, results_val[y_hat_name]), 3)}\", bbox=props)\n",
    "    plt.savefig(f\"paper/plots/powerlaw_val_{y_hat_name}.jpg\")\n",
    "    plt.show()\n",
    "    print(\"rsquare val:\")\n",
    "    print(metrics.r2_score(results_val.accs, results_val[y_hat_name]))\n",
    "    print(1 - (1 - metrics.r2_score(results_val.accs, results_val[y_hat_name])) * (xdata_val.shape[1] - 1) / (xdata_val.shape[1] - n_p - 1))\n",
    "\n",
    "    acc_pred = func_powerlaw(xpred, *params)\n",
    "    results_pred_orig[\"acc_pred\"] = acc_pred\n",
    "    sns.scatterplot(data = results_pred_orig, x = \"total_training_size\", y = \"acc_pred\", hue=\"epochs_trained\")\n",
    "    plt.show()\n",
    "    display(results_pred_orig.head(30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "c9bcba196a01498016ccd64548f4c665ee450ddca7e9d0b8c7efd8e8a933354c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
